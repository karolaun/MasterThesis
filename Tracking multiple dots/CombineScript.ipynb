{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Want to:**\n",
    "\n",
    "Fetch frames from two cameras and detect centers of colours\n",
    "\n",
    "Collect camera calibration from xml file\n",
    "\n",
    "Triangulate\n",
    "\n",
    "Find depth of both camera\n",
    "\n",
    "(Have to do two colllection- and finding centers for cameras, and also find depth for both layers with two different colours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "import cv2\n",
    "import argparse\n",
    "from imutils.video import VideoStream\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calibrating*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize = (9,6)\n",
    "frameSize = (1080,1920)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "objp *= (8,7.5,0) #Size of squares in chessboard\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "imagesLeft = glob.glob('Week16/Calib/left/*.png')\n",
    "imagesRight = glob.glob('Week16/Calib/right/*.png')\n",
    "\n",
    "imagesLeft = sorted(imagesLeft)\n",
    "imagesRight = sorted(imagesRight)\n",
    "\n",
    "index =0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\n",
    "    imgL = cv2.imread(imgLeft)\n",
    "    imgR = cv2.imread(imgRight)\n",
    "    grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "    grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv2.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv2.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv2.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv2.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        #cv2.imshow('img left', imgL)\n",
    "        image_nameL = \"Week16/calibres\" + '/resL' + str(index) + '.png'\n",
    "        cv2.imwrite(image_nameL, imgL)\n",
    "        cv2.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        #cv2.imshow('img right', imgR)\n",
    "        image_nameR = \"Week16/calibres\" + '/resR' + str(index) + '.png'\n",
    "        cv2.imwrite(image_nameR, imgL)\n",
    "        cv2.waitKey(1000)\n",
    "        index+=1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "############## CALIBRATION #######################################################\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv2.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv2.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv2.calibrateCamera(objpoints, imgpointsR, frameSize,None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv2.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Stereo Vision Calibration #############################################\n",
    "\n",
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "\n",
    "criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv2.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "########## Stereo Rectification #################################################\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv2.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv2.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv2.CV_16SC2)\n",
    "stereoMapR = cv2.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv2.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv2.FileStorage('stereoMapW16_2.xml', cv2.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Error##########\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    " imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecsL[i], tvecsL[i], cameraMatrixL, distL)\n",
    " error = cv2.norm(imgpointsL[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    " mean_error += error\n",
    " \n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Collecting calibration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera parameters to undistort and rectify images\n",
    "cv_file = cv2.FileStorage()\n",
    "cv_file.open('stereoMapW16_2.xml', cv2.FileStorage_READ)\n",
    "\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()\n",
    "\n",
    "def undistortRectify(frameR, frameL):\n",
    "    undistortedL= cv2.remap(frameL, stereoMapL_x, stereoMapL_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    undistortedR= cv2.remap(frameR, stereoMapR_x, stereoMapR_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    return undistortedR, undistortedL\n",
    "\n",
    "\n",
    "imgL = cv2.undistort(imgL, cameraMatrixL, distL, None, newCameraMatrixL)\n",
    "\n",
    "plt.imshow(imgL)\n",
    "plt.show()\n",
    "\n",
    "imgR = cv2.undistort(imgR, cameraMatrixR, distR, None, newCameraMatrixR)\n",
    "\n",
    "plt.imshow(imgR)\n",
    "plt.show()\n",
    "\n",
    "undistR,undistL = undistortRectify(imgR,imgL)\n",
    "plt.imshow(undistR)\n",
    "plt.show()\n",
    "plt.imshow(undistL)\n",
    "\n",
    "print(undistR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Triangulation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_depth(right_point, left_point, frame_right, frame_left, baseline,f, alpha):\n",
    "\n",
    "    # CONVERT FOCAL LENGTH f FROM [mm] TO [pixel]:\n",
    "    height_right, width_right, depth_right = frame_right.shape\n",
    "    height_left, width_left, depth_left = frame_left.shape\n",
    "\n",
    "    if width_right == width_left:\n",
    "        f_pixel = (width_right * 0.5) / np.tan(alpha * 0.5 * np.pi/180)\n",
    "\n",
    "    else:\n",
    "        print('Left and right camera frames do not have the same pixel width')\n",
    "    x_right, _ = right_point[0]  # Extract x-coordinate from tuple\n",
    "    x_left, _ = left_point[0]  # Extract x-coordinate from tuple\n",
    "\n",
    "    # CALCULATE THE DISPARITY:\n",
    "    disparity = x_left-x_right      #Displacement between left and right frames [pixels]\n",
    "\n",
    "    # CALCULATE DEPTH z:\n",
    "    zDepth = (baseline*f_pixel)/disparity             #Depth in [cm]\n",
    "\n",
    "    return zDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Semi-global matching (SGBM/SGM) by Kevin Wood on youtube or kevinwoddrobotics on github\n",
    "class DepthMap:\n",
    "    def __init__(self,showImages):\n",
    "        root = os.getcwd()\n",
    "        imgLeftPath = os.path.join(root,\"Week16/Calib/left/framel0.png\")\n",
    "        imgRightpath = os.path.join(root,\"Week16/Calib/right/framer0.png\")\n",
    "        self.imgLeft = cv2.imread(imgLeftPath,cv2.IMREAD_GRAYSCALE)\n",
    "        self.imgRight = cv2.imread(imgRightpath,cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if showImages:\n",
    "            plt.figure()\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(self.imgLeft)\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(self.imgRight)\n",
    "            plt.show()\n",
    "\n",
    "    def computedepthmapBM(self):\n",
    "        ndispfactor = 12 #adjust\n",
    "        stereo = cv2.StereoBM.create(numDisparities=16*ndispfactor,blockSize=21)\n",
    "        disparity = stereo.compute(self.imgLeft,self.imgRight)\n",
    "        plt.imshow(disparity,\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "    def computedepthmapSGBM(self):\n",
    "        windowsize = 7\n",
    "        min_disp = 16\n",
    "        ndispfactor = 14\n",
    "        num_disp = 16*ndispfactor-min_disp\n",
    "        stereo = cv2.StereoSGBM_create(minDisparity=min_disp,numDisparities=num_disp,blockSize=windowsize,P1 = 8*3*windowsize**2,P2=32*3*windowsize**2,disp12MaxDiff=1,uniquenessRatio=15,speckleWindowSize=0,speckleRange=2,preFilterCap=63,mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
    "        \n",
    "        disparity = stereo.compute(self.imgLeft,self.imgRight).astype(np.float32)/16\n",
    "        plt.imshow(disparity)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "def demoStereoBM():\n",
    "    dp = DepthMap(showImages=False)\n",
    "    dp.computedepthmapBM()\n",
    "\n",
    "def demoStereoSGBM():\n",
    "    dp = DepthMap(showImages=False)\n",
    "    dp.computedepthmapSGBM()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demoStereoBM()\n",
    "    demoStereoSGBM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 1920\n",
    "real_heightobj = 3.4 #mm\n",
    "f = 3.67\n",
    "obj_heightpx = 44 #px from GIMP\n",
    "\n",
    "def find_depth2(real_heightobj, img_height,f,obj_heightpx):\n",
    "    sensorh = 1/2.88 #inches = (1inch = 25.4mm)\n",
    "    #1px = 0.2645833333mm\n",
    "    sensord = 16 * sensorh\n",
    "    h = 9*np.sqrt(sensord**2 / 337)\n",
    "    d = (f * real_heightobj * img_height)/(obj_heightpx * h)\n",
    "    return d\n",
    "\n",
    "d = find_depth2(img_height,real_heightobj,f,obj_heightpx)\n",
    "\n",
    "print(\"The object is: \",d/10,\"cm away from the camera\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def masker(frame, lower, upper):\n",
    "    mask = cv2.inRange(frame, lower, upper)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    return mask\n",
    "\n",
    "def calculate_centers(contours):\n",
    "    return [(x + w // 2, y + h // 2) for contour in contours for x, y, w, h in map(cv2.boundingRect, contours)]\n",
    "\n",
    "def filter_centers(centers, colour,side,limit, index):\n",
    "    try: \n",
    "        for i, center in enumerate(centers):\n",
    "            res = f\"./Week16/{colour}/res{side}{i}.txt\"\n",
    "            if index == 0:\n",
    "                with open(res, \"w\") as file:\n",
    "                    print(f\"{center[0]},{center[1]}\", file=file)\n",
    "            else:\n",
    "                with open(res, \"r\") as file:\n",
    "                    lines = file.readlines()\n",
    "                if lines:\n",
    "                    prev_x, prev_y = map(float, lines[-1].strip().split(\",\"))\n",
    "                    if abs(center[0] - prev_x) <= limit and abs(center[1] - prev_y) <= limit:\n",
    "                        with open(res, \"a\") as file:\n",
    "                            print(f\"{center[0]},{center[1]}\", file=file)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "def extract_coordinates(content):\n",
    "    # Define a regular expression pattern to match coordinates\n",
    "    pattern = r'(\\d+),(\\d+)'\n",
    "    \n",
    "    # Find all occurrences of coordinates in the content\n",
    "    coordinates = re.findall(pattern, content)\n",
    "    # Convert the coordinates from strings to integers\n",
    "    coordinates = [(int(x), int(y)) for x, y in coordinates]\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "def displaydepth(frameleft,frameright,centersl,centersr,B,f,alpha):\n",
    "    if not centersr or not centersl:\n",
    "        cv2.putText(frameright, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255),2)\n",
    "        cv2.putText(frameleft, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255),2)\n",
    "        return frameleft,frameright,\"error no depth\"\n",
    "    else:\n",
    "    # Function to calculate depth of object. Outputs vector of all depths in case of several balls.\n",
    "    # All formulas used to find depth is in video presentaion\n",
    "        depth = find_depth(centersr, centersl, frameright, frameleft, B, f, alpha)\n",
    "\n",
    "        cv2.putText(frameright, \"TRACKING\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (124,252,0),2)\n",
    "        cv2.putText(frameleft, \"TRACKING\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (124,252,0),2)\n",
    "        cv2.putText(frameright, \"Distance: \" + str(round(depth,3)), (200,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (124,252,0),2)\n",
    "        cv2.putText(frameleft, \"Distance: \" + str(round(depth,3)), (200,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (124,252,0),2)\n",
    "        # Multiply computer value with 205.8 to get real-life depth in [cm]. The factor was found manually.\n",
    "        return frameleft,frameright,depth\n",
    "\n",
    "depths = []   \n",
    "def calculate_depths(frame_right,frame_left,baseline,f_pixel,alpha,folder_pathl,folder_pathr):\n",
    "\n",
    "    def collect_coords(folder_path):\n",
    "        files = os.listdir(folder_path)\n",
    "        for file in files:\n",
    "                file_path = sorted(os.path.join(folder_path, file))\n",
    "                # Check if the file is a regular file (not a directory)\n",
    "                if os.path.isfile(file_path):\n",
    "                    # Extract coordinates from the file\n",
    "                    coordinates = extract_coordinates(file_path)\n",
    "                    print(coordinates)\n",
    "        return coordinates\n",
    "\n",
    "    left_coords = collect_coords(folder_pathl)\n",
    "    right_coords = collect_coords(folder_pathr)\n",
    "    for leftcoord, rightcoord in zip(left_coords, right_coords):\n",
    "        # Calculate depth for the pair of points\n",
    "        depth = find_depth(leftcoord, rightcoord, frame_right,frame_left,baseline,f_pixel,alpha)\n",
    "        # Append the depth to the depths list\n",
    "        depths.append(depth)\n",
    "\n",
    "    return depths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Main*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    red_lower = np.array([0, 100, 122], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    green_lower = np.array([35, 20, 16], np.uint8)\n",
    "    green_upper = np.array([110, 196, 197], np.uint8)\n",
    "\n",
    "    \n",
    "    paused = False\n",
    "    index = 0\n",
    "\n",
    "    vl_path = \"Week16/left2.avi\"\n",
    "    vr_path = \"Week16/right2.avi\"\n",
    "    \n",
    "    vl = cv2.VideoCapture(vl_path)\n",
    "    vr = cv2.VideoCapture(vr_path)\n",
    "\n",
    "    while True:\n",
    "        if not paused:\n",
    "            retl, framel = vl.read()\n",
    "            retr, framer = vr.read()\n",
    "            if not retl or not retr:\n",
    "                print(\"End of video\")\n",
    "                break\n",
    "\n",
    "        framer,framel = undistortRectify(framer,framel)\n",
    "        hsvl = cv2.cvtColor(framel, cv2.COLOR_BGR2HSV)\n",
    "        hsvr = cv2.cvtColor(framer,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        mask_greenL = masker(hsvl, green_lower, green_upper)\n",
    "        mask_redL = masker(hsvl, red_lower, red_upper)\n",
    "        mask_greenR = masker(hsvr, green_lower, green_upper)\n",
    "        mask_redR = masker(hsvr, red_lower, red_upper)\n",
    "\n",
    "        contours_greenL, _ = cv2.findContours(mask_greenL.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_redL, _ = cv2.findContours(mask_redL.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        green_dot_centersL = calculate_centers(contours_greenL)\n",
    "        red_dot_centersL = calculate_centers(contours_redL)\n",
    "\n",
    "        contours_greenR, _ = cv2.findContours(mask_greenR.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_redR, _ = cv2.findContours(mask_redR.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        green_dot_centersR = calculate_centers(contours_greenR)\n",
    "        red_dot_centersR = calculate_centers(contours_redR)\n",
    "\n",
    "        #filter_centers(red_dot_centersL, \"Red\",\"l\", 20, index)\n",
    "        #filter_centers(green_dot_centersL, \"Green\",\"l\", 20, index)\n",
    "        #filter_centers(red_dot_centersR,\"Red\",\"r\",20,index)\n",
    "        #filter_centers(green_dot_centersR,\"Green\",\"r\",20,index)\n",
    "\n",
    "        for center in green_dot_centersL:\n",
    "            cv2.circle(framel, center, 3, (0, 255, 0), -1)\n",
    "        for center in red_dot_centersL:\n",
    "            cv2.circle(framel, center, 3, (255, 255, 255), -1)\n",
    "\n",
    "        for center in green_dot_centersR:\n",
    "            cv2.circle(framer, center, 3, (0, 255, 0), -1)\n",
    "        for center in red_dot_centersR:\n",
    "            cv2.circle(framer, center, 3, (255, 255, 255), -1)\n",
    "\n",
    "        #name = f\"./Week15/Frameres/framer{index}.png\"\n",
    "        #cv2.imwrite(name, framer)\n",
    "    \n",
    "                    \n",
    "        #depthsRed = calculate_depths(framer,framel,B,f_pixel,alpha)\n",
    "        #depthsGreen = calculate_depths(framer,framel,B,f_pixel,alpha,\"Week16/Green/left\",\"Week16/Green/right\")\n",
    "        #print(depthsGreen)\n",
    "        \n",
    "        framel,framer, depthRed = displaydepth(framel,framer,red_dot_centersL,red_dot_centersR,B,f_pixel,alpha)\n",
    "        framel,framer, depthGreen = displaydepth(framel,framer,green_dot_centersL,green_dot_centersR,B,f_pixel,alpha)\n",
    "        print(depthGreen,depthRed)\n",
    "    \n",
    "        cv2.imshow(\"Left\",framel)\n",
    "        cv2.imshow(\"Right\",framer)\n",
    "\n",
    "        index += 1\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"p\"):\n",
    "            paused = not paused\n",
    "            print(\"Paused\" if paused else \"Resumed\")\n",
    "        elif key == ord(\"d\"):\n",
    "            break\n",
    "\n",
    "    vl.release()\n",
    "    vr.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Stereo vision setup parameters\n",
    "frame_rate = 30     #Camera frame rate\n",
    "B = 2.7             #Distance between the cameras [cm]\n",
    "f = 3.67            #Camera lense's focal length [mm]\n",
    "alpha = 78          #Camera field of view in the horisontal plane [degrees]\n",
    "f_pixel = f * (1080/((1/2.88)*25.4))\n",
    "#Camera focal length is 3.67mm for 920 pro and 78 degrees camera field of view\n",
    "#For c930 it is approximately the same and 90 degrees camera field of view\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    red_lower = np.array([0, 100, 122], np.uint8)\n",
    "    red_upper = np.array([180, 255, 255], np.uint8)\n",
    "    green_lower = np.array([35, 20, 16], np.uint8)\n",
    "    green_upper = np.array([110, 196, 197], np.uint8)\n",
    "\n",
    "    \n",
    "    paused = False\n",
    "    index = 0\n",
    "\n",
    "    vl_path = \"Week16/left2.avi\"\n",
    "    vr_path = \"Week16/right2.avi\"\n",
    "    \n",
    "    vl = cv2.VideoCapture(vl_path)\n",
    "    vr = cv2.VideoCapture(vr_path)\n",
    "\n",
    "    f = open(\"Week16/RedAllLeft.txt\",\"w\")\n",
    "    f2 = open(\"Week16/RedAllRight.txt\",\"w\")\n",
    "    f3 = open(\"Week16/GreenAllRight.txt\",\"w\")\n",
    "    f4= open(\"Week16/GreenAllLeft.txt\",\"w\")\n",
    "\n",
    "    while True:\n",
    "        if not paused:\n",
    "            retl, framel = vl.read()\n",
    "            retr, framer = vr.read()\n",
    "            if not retl or not retr:\n",
    "                print(\"End of video\")\n",
    "                break\n",
    "\n",
    "        framer,framel = undistortRectify(framer,framel)\n",
    "        hsvl = cv2.cvtColor(framel, cv2.COLOR_BGR2HSV)\n",
    "        hsvr = cv2.cvtColor(framer,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        mask_greenL = masker(hsvl, green_lower, green_upper)\n",
    "        mask_redL = masker(hsvl, red_lower, red_upper)\n",
    "        mask_greenR = masker(hsvr, green_lower, green_upper)\n",
    "        mask_redR = masker(hsvr, red_lower, red_upper)\n",
    "\n",
    "        contours_greenL, _ = cv2.findContours(mask_greenL.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_redL, _ = cv2.findContours(mask_redL.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        green_dot_centersL = calculate_centers(contours_greenL)\n",
    "        red_dot_centersL = calculate_centers(contours_redL)\n",
    "\n",
    "        contours_greenR, _ = cv2.findContours(mask_greenR.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_redR, _ = cv2.findContours(mask_redR.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        green_dot_centersR = calculate_centers(contours_greenR)\n",
    "        red_dot_centersR = calculate_centers(contours_redR)\n",
    "\n",
    "        #filter_centers(red_dot_centersL, \"Red\",\"l\", 20, index)\n",
    "        #filter_centers(green_dot_centersL, \"Green\",\"l\", 20, index)\n",
    "        #filter_centers(red_dot_centersR,\"Red\",\"r\",20,index)\n",
    "        #filter_centers(green_dot_centersR,\"Green\",\"r\",20,index)\n",
    "\n",
    "        for center in green_dot_centersL:\n",
    "            cv2.circle(framel, center, 3, (0, 255, 0), -1)\n",
    "        for center in red_dot_centersL:\n",
    "            cv2.circle(framel, center, 3, (255, 255, 255), -1)\n",
    "\n",
    "        for center in green_dot_centersR:\n",
    "            cv2.circle(framer, center, 3, (0, 255, 0), -1)\n",
    "        for center in red_dot_centersR:\n",
    "            cv2.circle(framer, center, 3, (255, 255, 255), -1)\n",
    "\n",
    "        #name = f\"./Week15/Frameres/framer{index}.png\"\n",
    "        #cv2.imwrite(name, framer)\n",
    "    \n",
    "                    \n",
    "        #depthsRed = calculate_depths(framer,framel,B,f_pixel,alpha)\n",
    "        #depthsGreen = calculate_depths(framer,framel,B,f_pixel,alpha,\"Week16/Green/left\",\"Week16/Green/right\")\n",
    "        #print(depthsGreen)\n",
    "        \n",
    "        framel,framer, depthRed = displaydepth(framel,framer,red_dot_centersL,red_dot_centersR,B,f_pixel,alpha)\n",
    "        framel,framer, depthGreen = displaydepth(framel,framer,green_dot_centersL,green_dot_centersR,B,f_pixel,alpha)\n",
    "        print(depthGreen,depthRed)\n",
    "\n",
    "        #with open(\"Week16/Depth.txt\",\"a\") as file2:\n",
    "        #    print(depthGreen,\",\",depthRed,file=file2)\n",
    "        left_frame_line_r = \" \".join([f\"{x},{y}\" for x, y in red_dot_centersL])\n",
    "        right_frame_line_r = ' '.join([f\"{x},{y}\" for x, y in red_dot_centersR])\n",
    "        left_frame_line_g = \" \".join([f\"{x},{y}\" for x, y in green_dot_centersL])\n",
    "        right_frame_line_g = ' '.join([f\"{x},{y}\" for x, y in green_dot_centersR])\n",
    "        f.write(f\"{left_frame_line_r}\\n\")\n",
    "        f2.write(f\"{right_frame_line_r}\\n\")\n",
    "        f3.write(f\"{right_frame_line_g}\\n\")\n",
    "        f4.write(f\"{left_frame_line_g}\\n\")\n",
    "\n",
    "        index += 1\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"p\"):\n",
    "            paused = not paused\n",
    "            print(\"Paused\" if paused else \"Resumed\")\n",
    "        elif key == ord(\"d\"):\n",
    "            break\n",
    "\n",
    "    f.close()\n",
    "    f2.close()\n",
    "    f3.close()\n",
    "    f4.close()\n",
    "\n",
    "    vl.release()\n",
    "    vr.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Stereo vision setup parameters\n",
    "frame_rate = 30     #Camera frame rate\n",
    "B = 2.7             #Distance between the cameras [cm]\n",
    "f = 3.67            #Camera lense's focal length [mm]\n",
    "alpha = 78          #Camera field of view in the horisontal plane [degrees]\n",
    "f_pixel = f * (1080/((1/2.88)*25.4))\n",
    "#Camera focal length is 3.67mm for 920 pro and 78 degrees camera field of view\n",
    "#For c930 it is approximately the same and 90 degrees camera field of view\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencvmaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
