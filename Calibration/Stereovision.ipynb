{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import yaml\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stereo calibration (Nicolai Nielsen: https://www.youtube.com/watch?v=KOSS24P3_fY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "chessboard_size = (9,6)\n",
    "frame_size = (480,640)\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((chessboard_size[0]*chessboard_size[1],3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboard_size[0],0:chessboard_size[1]].T.reshape(-1,2)\n",
    "\n",
    "objp = objp*20\n",
    "\n",
    "\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = []\n",
    "\n",
    "\n",
    "imagesL = glob.glob(r'CamVid/Left3/*.jpg')\n",
    "imagesR = glob.glob(r'CamVid/Right3/*.jpg')\n",
    "\n",
    "imagesL = sorted(imagesL)\n",
    "imagesR = sorted(imagesR)\n",
    "\n",
    "path = 'CamVid/calibres2'\n",
    "pathlib.Path(path).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "##Chessboard detection##\n",
    "found=0\n",
    "\n",
    "for imgl,imgr in zip(imagesL,imagesR):\n",
    "    imL = cv.imread(imgl)\n",
    "    imR = cv.imread(imgr)\n",
    "    grayL = cv.cvtColor(imL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imR, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboard_size, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboard_size, None)\n",
    "    #print(cornersL)\n",
    "    #print(cornersR)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "        objpoints.append(objp)   # Certainly, every loop objp is the same, in 3D.\n",
    "        cornersL = cv.cornerSubPix(grayL,cornersL,(11,11),(-1,-1),criteria)\n",
    "        cornersR = cv.cornerSubPix(grayR,cornersR,(11,11),(-1,-1),criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "        imgpointsR.append(cornersR)\n",
    "        # Draw and display the corners\n",
    "        imgL = cv.drawChessboardCorners(imL, chessboard_size, cornersL, retL)\n",
    "        imgR = cv.drawChessboardCorners(imR, chessboard_size, cornersR, retR)\n",
    "        #plt.imshow(imgL)\n",
    "        #plt.show()\n",
    "        #plt.imshow(imgR)\n",
    "        #plt.show()\n",
    "        image_nameL = path + '/calibresultL' + str(found) + '.png'\n",
    "        cv.imwrite(image_nameL, imgL)\n",
    "        image_nameR = path + \"/calibresultR\" + str(found) + \".png\"\n",
    "        cv.imwrite(image_nameR,imgR)\n",
    "        found += 1\n",
    "\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord(\"d\"):\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "##Calibration##\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints,imgpointsL,frame_size,None,None)\n",
    "heightL,widthL,channelsL = imL.shape\n",
    "newCameraMatrixL,roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL,distL,(widthL,heightL),1,(widthL,heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints,imgpointsR,frame_size,None,None)\n",
    "heightR,widthR,channelsR = imR.shape\n",
    "newCameraMatrixR,roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR,distR,(widthR,heightR),1,(widthR,heightR))\n",
    "\n",
    "##Stereo calibration##\n",
    "\n",
    "flags=0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "\n",
    "criteria_stereo = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "retstereo, newCameraMatrixL,distL,newCameraMatrixR,distR,rot,trans,essentialMatrix,fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "\n",
    "########## Stereo Rectification #################################################\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv.FileStorage('stereoMap4.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam1 not found\n",
      "cam2 not found\n",
      "cam1 not found\n",
      "cam2 not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# Camera parameters to undistort and rectify images\n",
    "cv_file = cv2.FileStorage()\n",
    "cv_file.open('stereoMap4.xml', cv2.FileStorage_READ)\n",
    "\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()\n",
    "\n",
    "# Capture from the first camera\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture from the second camera\n",
    "cap2 = cv2.VideoCapture(1)\n",
    "\n",
    "index=0\n",
    "\n",
    "while True:\n",
    "    # Read frames from both cameras\n",
    "    ret1, frame_right = cap1.read()\n",
    "    ret2, frame_left = cap2.read()\n",
    "    frame_right = cv2.remap(frame_right, stereoMapR_x, stereoMapR_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    frame_left = cv2.remap(frame_left, stereoMapL_x, stereoMapL_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "    if ret1:\n",
    "        cv2.imshow('Camera 1', frame_right)\n",
    "    else:\n",
    "        print(\"cam1 not found\")\n",
    "    if ret2:\n",
    "        cv2.imshow('Camera 2', frame_left)\n",
    "    else: print(\"cam2 not found\")\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF \n",
    "    if key == ord(\"d\"):\n",
    "        break\n",
    "    \n",
    "    index +=1\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth, from here: https://github.com/niconielsen32/ComputerVision/blob/master/StereoVisionDepthEstimation/triangulation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Function for stereo vision and depth estimation\n",
    "\n",
    "def find_depth(right_point, left_point, frame_right, frame_left, baseline,f, alpha):\n",
    "\n",
    "    # CONVERT FOCAL LENGTH f FROM [mm] TO [pixel]:\n",
    "    height_right, width_right, depth_right = frame_right.shape\n",
    "    height_left, width_left, depth_left = frame_left.shape\n",
    "\n",
    "    if width_right == width_left:\n",
    "        f_pixel = (width_right * 0.5) / np.tan(alpha * 0.5 * np.pi/180)\n",
    "\n",
    "    else:\n",
    "        print('Left and right camera frames do not have the same pixel width')\n",
    "\n",
    "    x_right = right_point[0]\n",
    "    x_left = left_point[0]\n",
    "\n",
    "    # CALCULATE THE DISPARITY:\n",
    "    disparity = x_left-x_right      #Displacement between left and right frames [pixels]\n",
    "\n",
    "    # CALCULATE DEPTH z:\n",
    "    zDepth = (baseline*f_pixel)/disparity             #Depth in [cm]\n",
    "\n",
    "    return zDepth\n",
    "\n",
    "# Camera parameters to undistort and rectify images\n",
    "cv_file = cv2.FileStorage()\n",
    "cv_file.open('stereoMap1.xml', cv2.FileStorage_READ)\n",
    "\n",
    "stereoMapL_x = cv_file.getNode('stereoMapL_x').mat()\n",
    "stereoMapL_y = cv_file.getNode('stereoMapL_y').mat()\n",
    "stereoMapR_x = cv_file.getNode('stereoMapR_x').mat()\n",
    "stereoMapR_y = cv_file.getNode('stereoMapR_y').mat()\n",
    "\n",
    "\n",
    "def undistortRectify(frameR, frameL):\n",
    "\n",
    "    # Undistort and rectify images\n",
    "    undistortedL= cv2.remap(frameL, stereoMapL_x, stereoMapL_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    undistortedR= cv2.remap(frameR, stereoMapR_x, stereoMapR_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "\n",
    "\n",
    "    return undistortedR, undistortedL\n",
    "\n",
    "# Mediapipe for face detection\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "mp_facedetector = mp.solutions.face_detection\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Open both cameras\n",
    "cap_right = cv2.VideoCapture(0, cv2.CAP_DSHOW)                    \n",
    "cap_left =  cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "# Stereo vision setup parameters\n",
    "frame_rate = 120    #Camera frame rate (maximum at 120 fps)\n",
    "B = 9               #Distance between the cameras [cm]\n",
    "f = 8              #Camera lense's focal length [mm]\n",
    "alpha = 56.6        #Camera field of view in the horisontal plane [degrees]\n",
    "\n",
    "# Main program loop with face detector and depth estimation using stereo vision\n",
    "with mp_facedetector.FaceDetection(min_detection_confidence=0.7) as face_detection:\n",
    "\n",
    "    while(cap_right.isOpened() and cap_left.isOpened()):\n",
    "\n",
    "        succes_right, frame_right = cap_right.read()\n",
    "        succes_left, frame_left = cap_left.read()\n",
    "\n",
    "    ################## CALIBRATION #########################################################\n",
    "\n",
    "        frame_right, frame_left = undistortRectify(frame_right, frame_left)\n",
    "\n",
    "    ########################################################################################\n",
    "\n",
    "        # If cannot catch any frame, break\n",
    "        if not succes_right or not succes_left:                    \n",
    "            break\n",
    "\n",
    "        else:\n",
    "\n",
    "            start = time.time()\n",
    "            \n",
    "            # Convert the BGR image to RGB\n",
    "            frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "            frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process the image and find faces\n",
    "            results_right = face_detection.process(frame_right)\n",
    "            results_left = face_detection.process(frame_left)\n",
    "\n",
    "            # Convert the RGB image to BGR\n",
    "            frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "            frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "            ################## CALCULATING DEPTH #########################################################\n",
    "\n",
    "            center_right = 0\n",
    "            center_left = 0\n",
    "\n",
    "            if results_right.detections:\n",
    "                for id, detection in enumerate(results_right.detections):\n",
    "                    mp_draw.draw_detection(frame_right, detection)\n",
    "\n",
    "                    bBox = detection.location_data.relative_bounding_box\n",
    "\n",
    "                    h, w, c = frame_right.shape\n",
    "\n",
    "                    boundBox = int(bBox.xmin * w), int(bBox.ymin * h), int(bBox.width * w), int(bBox.height * h)\n",
    "\n",
    "                    center_point_right = (boundBox[0] + boundBox[2] / 2, boundBox[1] + boundBox[3] / 2)\n",
    "\n",
    "                    cv2.putText(frame_right, f'{int(detection.score[0]*100)}%', (boundBox[0], boundBox[1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2)\n",
    "\n",
    "\n",
    "            if results_left.detections:\n",
    "                for id, detection in enumerate(results_left.detections):\n",
    "                    mp_draw.draw_detection(frame_left, detection)\n",
    "\n",
    "                    bBox = detection.location_data.relative_bounding_box\n",
    "\n",
    "                    h, w, c = frame_left.shape\n",
    "\n",
    "                    boundBox = int(bBox.xmin * w), int(bBox.ymin * h), int(bBox.width * w), int(bBox.height * h)\n",
    "\n",
    "                    center_point_left = (boundBox[0] + boundBox[2] / 2, boundBox[1] + boundBox[3] / 2)\n",
    "\n",
    "                    cv2.putText(frame_left, f'{int(detection.score[0]*100)}%', (boundBox[0], boundBox[1] - 20), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # If no ball can be caught in one camera show text \"TRACKING LOST\"\n",
    "            if not results_right.detections or not results_left.detections:\n",
    "                cv2.putText(frame_right, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "                cv2.putText(frame_left, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "\n",
    "            else:\n",
    "                # Function to calculate depth of object. Outputs vector of all depths in case of several balls.\n",
    "                # All formulas used to find depth is in video presentaion\n",
    "                depth = find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f, alpha)\n",
    "\n",
    "                cv2.putText(frame_right, \"Distance: \" + str(round(depth,1)), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0),3)\n",
    "                cv2.putText(frame_left, \"Distance: \" + str(round(depth,1)), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0),3)\n",
    "                # Multiply computer value with 205.8 to get real-life depth in [cm]. The factor was found manually.\n",
    "                print(\"Depth: \", str(round(depth,1)))\n",
    "\n",
    "            end = time.time()\n",
    "            totalTime = end - start\n",
    "\n",
    "            fps = 1 / totalTime\n",
    "            #print(\"FPS: \", fps)\n",
    "\n",
    "            cv2.putText(frame_right, f'FPS: {int(fps)}', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)\n",
    "            cv2.putText(frame_left, f'FPS: {int(fps)}', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)                                   \n",
    "\n",
    "\n",
    "            # Show the frames\n",
    "            cv2.imshow(\"frame right\", frame_right) \n",
    "            cv2.imshow(\"frame left\", frame_left)\n",
    "\n",
    "\n",
    "            # Hit \"q\" to close the window\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "cap_right.release()\n",
    "cap_left.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencvmaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
